{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJmnQV-RlAHB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, precision_score, recall_score, mean_absolute_error\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.datasets import load_iris\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "data = pd.DataFrame(\n",
        "    data=iris.data,\n",
        "    columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        ")\n",
        "# Introduce missing values for testing\n",
        "np.random.seed(42)\n",
        "mask = np.random.random(data.shape) < 0.1  # 10% missing\n",
        "data[mask] = np.nan\n",
        "data.to_csv('data.csv', index=False)"
      ],
      "metadata": {
        "id": "6ya3Pqaq8JzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['sepal_length','petal_length']].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "OomUunyU95X-",
        "outputId": "2a562e6e-9797-48f9-a7e3-4d73291f8b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal_length    5.866929\n",
              "petal_length    3.737879\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sepal_length</th>\n",
              "      <td>5.866929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>petal_length</th>\n",
              "      <td>3.737879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['sepal_width'].median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTxc1XNf-Fvw",
        "outputId": "f182adec-fd52-413a-c012-f53a2a7ddf27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sample_data(output_file='output.csv', missing_rate=0.1, target_col='petal_width', random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    iris = load_iris()\n",
        "    columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "    data = pd.DataFrame(data=iris.data, columns=columns)\n",
        "\n",
        "    feature_cols = [col for col in columns if col != target_col]\n",
        "    mask = np.random.rand(*data[feature_cols].shape) < missing_rate\n",
        "    data.loc[:, feature_cols] = data.loc[:, feature_cols].mask( mask)\n",
        "\n",
        "    data.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Dataset with missing values saved to '{output_file}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_sample_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4muIajhUoEzt",
        "outputId": "115079a2-4e05-427a-dc71-bbe1c0597141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset with missing values saved to 'output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algoparams_from_ui = {\n",
        "    \"target\": {\n",
        "        \"prediction_type\": \"Regression\",\n",
        "        \"target\": \"petal_width\",\n",
        "        \"type\": \"regression\",\n",
        "        \"partitioning\": True\n",
        "    },\n",
        "    \"feature_handling\": {\n",
        "        \"sepal_length\": {\n",
        "            \"feature_name\": \"sepal_length\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Average of values\",\n",
        "                \"impute_value\": 5.86\n",
        "            }\n",
        "        },\n",
        "        \"sepal_width\": {\n",
        "            \"feature_name\": \"sepal_width\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Constant\",\n",
        "                \"impute_value\": 3\n",
        "            }\n",
        "        },\n",
        "        \"petal_length\": {\n",
        "            \"feature_name\": \"petal_length\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Average of values\",\n",
        "                \"impute_value\": 3.73\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"feature_reduction\": {\n",
        "        \"feature_reduction_method\": \"Correlation with target\",\n",
        "        \"No Reduction\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 5\n",
        "        },\n",
        "        \"Correlation with target\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 2,\n",
        "            \"threshold\": 0.5\n",
        "        },\n",
        "        \"Tree-based\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 2,\n",
        "            \"depth_of_trees\": 10,\n",
        "            \"num_of_trees\": 100\n",
        "        },\n",
        "        \"Principal Component Analysis\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 2\n",
        "        }\n",
        "    },\n",
        "    \"models\": [\n",
        "        {\n",
        "            \"model_name\": \"LinearRegression\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"fit_intercept\": [True, False]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"model_name\": \"RandomForestRegressor\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"n_estimators\": [50, 100, 150, 200],\n",
        "                \"max_depth\": [None, 10, 20, 30],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 2, 4],\n",
        "                \"max_features\": [\"sqrt\", \"log2\", 0.5, None],\n",
        "                \"bootstrap\": [True],\n",
        "                \"max_samples\": [None, 0.5, 0.75],  # Controls sample size per tree\n",
        "                \"warm_start\": [True, False]  # Allows adding more trees\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"model_name\": \"DecisionTreeRegressor\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "                \"splitter\": [\"best\", \"random\"],\n",
        "                \"max_depth\": [None, 5, 10, 20],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 2, 4],\n",
        "                \"max_features\": [None, \"sqrt\", \"log2\", 0.5]\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"hyperparameters\": {\n",
        "        \"search_method\": \"Grid Search\",\n",
        "        \"Grid Search\": {\n",
        "            \"is_selected\": True,\n",
        "            \"shuffle_grid\": True,\n",
        "            \"random_state\": 0,\n",
        "            \"max_iterations\": 10,\n",
        "            \"max_search_time\": 0,\n",
        "            \"cross_validation_strategy\": \"Time-based K-fold(with overlap)\",\n",
        "            \"Time-based K-fold(with overlap)\": {\n",
        "                \"is_selected\": True,\n",
        "                \"num_of_folds\": 5,\n",
        "                \"split_ratio\": 0,\n",
        "                \"stratified\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"algoparams_from_ui.json\", \"w\") as file:\n",
        "    json.dump(algoparams_from_ui, file, indent=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "4EjRdAAA2TMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Custom Feature Reduction (Correlation with Target) ===\n",
        "class CorrelationThresholdSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, threshold=0.5, num_features=None):\n",
        "        self.threshold = threshold\n",
        "        self.num_features = num_features\n",
        "        self.selected_indices_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_np = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
        "        correlations = np.array([np.abs(np.corrcoef(X_np[:, i], y)[0, 1]) for i in range(X_np.shape[1])])\n",
        "        if self.num_features:\n",
        "            self.selected_indices_ = np.argsort(correlations)[-self.num_features:]\n",
        "        else:\n",
        "            self.selected_indices_ = np.where(correlations > self.threshold)[0]\n",
        "        if len(self.selected_indices_) == 0:\n",
        "            self.selected_indices_ = np.arange(X_np.shape[1])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.iloc[:, self.selected_indices_] if isinstance(X, pd.DataFrame) else X[:, self.selected_indices_]\n",
        "\n",
        "# === Passthrough ===\n",
        "class PassthroughTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X): return X\n",
        "\n",
        "# === Config Load ===\n",
        "def load_config(file_path='/content/algoparams_from_ui.json'):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# === Data Load ===\n",
        "def load_data(config, file_path='output.csv'):\n",
        "    df = pd.read_csv(file_path)\n",
        "    target = config['target']['target']\n",
        "    features = [f for f, meta in config['feature_handling'].items() if meta['is_selected']]\n",
        "    df = df.dropna(subset=[target])\n",
        "    return df[features], df[target]\n",
        "\n",
        "# === Imputer Builder ===\n",
        "def create_imputer(config):\n",
        "    transformers = []\n",
        "    for feature, meta in config['feature_handling'].items():\n",
        "        if not meta['is_selected']: continue\n",
        "        method = meta['feature_details']['impute_with']\n",
        "        value = meta['feature_details']['impute_value']\n",
        "        if method == 'Average of values':\n",
        "            imp = SimpleImputer(strategy='mean')\n",
        "        elif method == 'Median of values':\n",
        "            imp = SimpleImputer(strategy='median')\n",
        "        elif method == 'Constant':\n",
        "            imp = SimpleImputer(strategy='constant', fill_value=value)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid impute method: {method}\")\n",
        "        transformers.append((f'imp_{feature}', imp, [feature]))\n",
        "    return ColumnTransformer(transformers, remainder='passthrough')\n",
        "\n",
        "# === Feature Reducer Builder ===\n",
        "def create_feature_reducer(config):\n",
        "    method = config['feature_reduction']['feature_reduction_method']\n",
        "    opts = config['feature_reduction'].get(method, {})\n",
        "    if method == 'No Reduction':\n",
        "        return PassthroughTransformer()\n",
        "    elif method == 'Principal Component Analysis':\n",
        "        return PCA(n_components=opts.get('num_of_features_to_keep', 2))\n",
        "    elif method == 'Correlation with target':\n",
        "        return CorrelationThresholdSelector(\n",
        "            threshold=opts.get('threshold', 0.5),\n",
        "            num_features=opts.get('num_of_features_to_keep')\n",
        "        )\n",
        "    elif method == 'Tree-based':\n",
        "        return SelectFromModel(\n",
        "            RandomForestRegressor(\n",
        "                n_estimators=opts.get('num_of_trees', 100),\n",
        "                max_depth=opts.get('depth_of_trees', 10),\n",
        "                random_state=0\n",
        "            ),\n",
        "            max_features=opts.get('num_of_features_to_keep', 2)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown feature reduction method: {method}\")\n",
        "\n",
        "# === Model Class Resolver ===\n",
        "def get_model_class(name, task):\n",
        "    if task == 'Regression':\n",
        "        return {\n",
        "            'LinearRegression': LinearRegression,\n",
        "            'RandomForestRegressor': RandomForestRegressor,\n",
        "            'DecisionTreeRegressor': DecisionTreeRegressor\n",
        "        }[name]\n",
        "    raise ValueError(f\"Unsupported prediction_type: {task}\")\n",
        "\n",
        "# === Main Pipeline Executor ===\n",
        "def main():\n",
        "    config = load_config()\n",
        "    X, y = load_data(config)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    imputer = create_imputer(config)\n",
        "    reducer = create_feature_reducer(config)\n",
        "    prediction_type = config['target']['prediction_type']\n",
        "\n",
        "    for model_conf in config['models']:\n",
        "        if not model_conf['is_selected']: continue\n",
        "        name = model_conf['model_name']\n",
        "        hyperparams = model_conf.get('hyperparameters', {})\n",
        "\n",
        "        # Handle bootstrap-max_samples conflict\n",
        "        if name == \"RandomForestRegressor\" and 'bootstrap' in hyperparams and 'max_samples' in hyperparams:\n",
        "            if False in hyperparams['bootstrap']:\n",
        "                print(f\"⚠️ Removing 'max_samples' because bootstrap=False is included for {name}\")\n",
        "                del hyperparams['max_samples']\n",
        "\n",
        "        model_class = get_model_class(name, prediction_type)\n",
        "        pipeline = Pipeline([\n",
        "            ('imputer', imputer),\n",
        "            ('reducer', reducer),\n",
        "            ('model', model_class())\n",
        "        ])\n",
        "\n",
        "        grid_params = {f\"model__{k}\": v for k, v in hyperparams.items()}\n",
        "        folds = config['hyperparameters']['Grid Search']['Time-based K-fold(with overlap)']['num_of_folds']\n",
        "\n",
        "        search = GridSearchCV(pipeline, grid_params, scoring='neg_mean_squared_error', cv=folds, n_jobs=-1)\n",
        "\n",
        "        try:\n",
        "            search.fit(X_train, y_train)\n",
        "            preds = search.predict(X_test)\n",
        "\n",
        "            print(f\"\\n✅ Model: {name}\")\n",
        "            print(f\"Best Params: {search.best_params_}\")\n",
        "            print(f\"MSE: {mean_squared_error(y_test, preds):.4f}\")\n",
        "            print(f\"MAE: {mean_absolute_error(y_test, preds):.4f}\")\n",
        "            print(f\"R2 Score: {r2_score(y_test, preds):.4f}\")\n",
        "            print(\"-\" * 60)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error with {name}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "PCdRYOnez3-g",
        "outputId": "99c25452-d6dc-4c38-d892-ce2ddf84331e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model: LinearRegression\n",
            "Best Params: {'model__fit_intercept': True}\n",
            "MSE: 0.1507\n",
            "MAE: 0.2766\n",
            "R2 Score: 0.7629\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-62481ce5a189>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-62481ce5a189>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xalgoparams_from_ui_={\n",
        "    \"target\": {\n",
        "        \"prediction_type\": \"Regression\",\n",
        "        \"target\": \"petal_width\",\n",
        "        \"type\": \"regression\",\n",
        "        \"partitioning\": True\n",
        "    },\n",
        "    \"feature_handling\": {\n",
        "        \"sepal_length\": {\n",
        "            \"feature_name\": \"sepal_length\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Average of values\",\n",
        "                \"impute_value\": 5.86\n",
        "            }\n",
        "        },\n",
        "        \"sepal_width\": {\n",
        "            \"feature_name\": \"sepal_width\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Constant\",\n",
        "                \"impute_value\": 3\n",
        "            }\n",
        "        },\n",
        "        \"petal_length\": {\n",
        "            \"feature_name\": \"petal_length\",\n",
        "            \"is_selected\": True,\n",
        "            \"feature_variable_type\": \"numerical\",\n",
        "            \"feature_details\": {\n",
        "                \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "                \"rescaling\": \"Standardize (mean=0, std=1)\",\n",
        "                \"make_derived_feats\": False,\n",
        "                \"missing_values\": \"Impute\",\n",
        "                \"impute_with\": \"Average of values\",\n",
        "                \"impute_value\": 3.73\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"feature_reduction\": {\n",
        "        \"feature_reduction_method\": \"Principal Component Analysis\",\n",
        "        \"No Reduction\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 5\n",
        "        },\n",
        "        \"Correlation with target\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 2,\n",
        "            \"threshold\": 0.5\n",
        "        },\n",
        "        \"Tree-based\": {\n",
        "            \"is_selected\": False,\n",
        "            \"num_of_features_to_keep\": 2,\n",
        "            \"depth_of_trees\": 10,\n",
        "            \"num_of_trees\": 100\n",
        "        },\n",
        "        \"Principal Component Analysis\": {\n",
        "            \"is_selected\": True,\n",
        "            \"num_of_features_to_keep\": 2\n",
        "        }\n",
        "    },\n",
        "    \"models\": [\n",
        "        {\n",
        "            \"model_name\": \"LinearRegression\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"fit_intercept\": [True, False]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"model_name\": \"RandomForestRegressor\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"n_estimators\": [50, 100, 150, 200],\n",
        "                \"max_depth\": [None, 10, 20, 30],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 2, 4],\n",
        "                \"max_features\": [\"sqrt\", \"log2\", 0.5, None],\n",
        "                \"bootstrap\": [True],\n",
        "                \"max_samples\": [None, 0.5, 0.75],\n",
        "                \"warm_start\": [True, False]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"model_name\": \"DecisionTreeRegressor\",\n",
        "            \"is_selected\": True,\n",
        "            \"hyperparameters\": {\n",
        "                \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "                \"splitter\": [\"best\", \"random\"],\n",
        "                \"max_depth\": [None, 5, 10, 20],\n",
        "                \"min_samples_split\": [2, 5, 10],\n",
        "                \"min_samples_leaf\": [1, 2, 4],\n",
        "                \"max_features\": [None, \"sqrt\", \"log2\", 0.5]\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"hyperparameters\": {\n",
        "        \"search_method\": \"Grid Search\",\n",
        "        \"Grid Search\": {\n",
        "            \"is_selected\": True,\n",
        "            \"shuffle_grid\": True,\n",
        "            \"random_state\": 0,\n",
        "            \"max_iterations\": 10,\n",
        "            \"max_search_time\": 0,\n",
        "            \"cross_validation_strategy\": \"Time-based K-fold(with overlap)\",\n",
        "            \"Time-based K-fold(with overlap)\": {\n",
        "                \"is_selected\": True,\n",
        "                \"num_of_folds\": 5,\n",
        "                \"split_ratio\": 0,\n",
        "                \"stratified\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "with open(\"algoparams_from_ui_.json\", \"w\") as file:\n",
        "    json.dump(algoparams_from_ui_, file, indent=4)"
      ],
      "metadata": {
        "id": "0J64JzN-wd6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def generate_sample_data(output_file='output.csv', missing_rate=0.1, target_col='petal_width', random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    iris = load_iris()\n",
        "    columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "    data = pd.DataFrame(data=iris.data, columns=columns)\n",
        "\n",
        "    feature_cols = [col for col in columns if col != target_col]\n",
        "    mask = np.random.rand(*data[feature_cols].shape) < missing_rate\n",
        "    data.loc[:, feature_cols] = data.loc[:, feature_cols].mask(mask)\n",
        "\n",
        "    data.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Dataset with missing values saved to '{output_file}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_sample_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOk-yrMu1qHj",
        "outputId": "febaa49f-a2d7-4389-cfdb-c2b044963b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset with missing values saved to 'output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CorrelationThresholdSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, threshold=0.5, num_features=None):\n",
        "        self.threshold = threshold\n",
        "        self.num_features = num_features\n",
        "        self.selected_indices_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_np = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
        "        correlations = np.array([np.abs(np.corrcoef(X_np[:, i], y)[0, 1]) for i in range(X_np.shape[1])])\n",
        "        if self.num_features:\n",
        "            self.selected_indices_ = np.argsort(correlations)[-self.num_features:]\n",
        "        else:\n",
        "            self.selected_indices_ = np.where(correlations > self.threshold)[0]\n",
        "        if len(self.selected_indices_) == 0:\n",
        "            self.selected_indices_ = np.arange(X_np.shape[1])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.iloc[:, self.selected_indices_] if isinstance(X, pd.DataFrame) else X[:, self.selected_indices_]\n",
        "\n",
        "class PassthroughTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X): return X\n",
        "\n",
        "def load_config(file_path='/content/algoparams_from_ui_.json'):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_data(config, file_path='output.csv'):\n",
        "    df = pd.read_csv(file_path)\n",
        "    target = config['target']['target']\n",
        "    features = [f for f, meta in config['feature_handling'].items() if meta['is_selected']]\n",
        "    df = df.dropna(subset=[target])\n",
        "    return df[features], df[target]\n",
        "\n",
        "def create_imputer(config):\n",
        "    transformers = []\n",
        "    for feature, meta in config['feature_handling'].items():\n",
        "        if not meta['is_selected']: continue\n",
        "        method = meta['feature_details']['impute_with']\n",
        "        value = meta['feature_details']['impute_value']\n",
        "        if method == 'Average of values':\n",
        "            imp = SimpleImputer(strategy='mean')\n",
        "        elif method == 'Median of values':\n",
        "            imp = SimpleImputer(strategy='median')\n",
        "        elif method == 'Constant':\n",
        "            imp = SimpleImputer(strategy='constant', fill_value=value)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid impute method: {method}\")\n",
        "        transformers.append((f'imp_{feature}', imp, [feature]))\n",
        "    return ColumnTransformer(transformers, remainder='passthrough')\n",
        "\n",
        "def create_feature_reducer(config):\n",
        "    method = config['feature_reduction']['feature_reduction_method']\n",
        "    opts = config['feature_reduction'].get(method, {})\n",
        "    if method == 'No Reduction':\n",
        "        return PassthroughTransformer()\n",
        "    elif method == 'Principal Component Analysis':\n",
        "        return PCA(n_components=opts.get('num_of_features_to_keep', 2))\n",
        "    elif method == 'Correlation with target':\n",
        "        return CorrelationThresholdSelector(\n",
        "            threshold=opts.get('threshold', 0.5),\n",
        "            num_features=opts.get('num_of_features_to_keep')\n",
        "        )\n",
        "    elif method == 'Tree-based':\n",
        "        return SelectFromModel(\n",
        "            RandomForestRegressor(\n",
        "                n_estimators=opts.get('num_of_trees', 100),\n",
        "                max_depth=opts.get('depth_of_trees', 10),\n",
        "                random_state=0\n",
        "            ),\n",
        "            max_features=opts.get('num_of_features_to_keep', 2)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown feature reduction method: {method}\")\n",
        "\n",
        "def get_model_class(name, task):\n",
        "    if task == 'Regression':\n",
        "        return {\n",
        "            'LinearRegression': LinearRegression,\n",
        "            'RandomForestRegressor': RandomForestRegressor,\n",
        "            'DecisionTreeRegressor': DecisionTreeRegressor\n",
        "        }[name]\n",
        "    raise ValueError(f\"Unsupported prediction_type: {task}\")\n",
        "\n",
        "def main():\n",
        "    config = load_config()\n",
        "    X, y = load_data(config)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    imputer = create_imputer(config)\n",
        "    reducer = create_feature_reducer(config)\n",
        "    prediction_type = config['target']['prediction_type']\n",
        "\n",
        "    for model_conf in config['models']:\n",
        "        if not model_conf['is_selected']: continue\n",
        "        name = model_conf['model_name']\n",
        "        hyperparams = model_conf.get('hyperparameters', {})\n",
        "\n",
        "        if name == \"RandomForestRegressor\" and 'bootstrap' in hyperparams and 'max_samples' in hyperparams:\n",
        "            if False in hyperparams['bootstrap']:\n",
        "                print(f\"⚠️ Removing 'max_samples' because bootstrap=False is included for {name}\")\n",
        "                del hyperparams['max_samples']\n",
        "\n",
        "        model_class = get_model_class(name, prediction_type)\n",
        "        pipeline = Pipeline([\n",
        "            ('imputer', imputer),\n",
        "            ('reducer', reducer),\n",
        "            ('model', model_class())\n",
        "        ])\n",
        "\n",
        "        grid_params = {f\"model__{k}\": v for k, v in hyperparams.items()}\n",
        "        folds = config['hyperparameters']['Grid Search']['Time-based K-fold(with overlap)']['num_of_folds']\n",
        "\n",
        "        search = GridSearchCV(pipeline, grid_params, scoring='neg_mean_squared_error', cv=folds, n_jobs=-1)\n",
        "\n",
        "        try:\n",
        "            search.fit(X_train, y_train)\n",
        "            preds = search.predict(X_test)\n",
        "\n",
        "            print(f\"\\n✅ Model: {name}\")\n",
        "            print(f\"Best Params: {search.best_params_}\")\n",
        "            print(f\"MSE: {mean_squared_error(y_test, preds):.4f}\")\n",
        "            print(f\"MAE: {mean_absolute_error(y_test, preds):.4f}\")\n",
        "            print(f\"R2 Score: {r2_score(y_test, preds):.4f}\")\n",
        "            print(\"-\" * 60)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error with {name}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GXm5tSq1kLg",
        "outputId": "a6657ebf-7ef4-4f88-ae46-951e27322e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model: LinearRegression\n",
            "Best Params: {'model__fit_intercept': True}\n",
            "MSE: 0.1535\n",
            "MAE: 0.2736\n",
            "R2 Score: 0.7586\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Model: RandomForestRegressor\n",
            "Best Params: {'model__bootstrap': True, 'model__max_depth': None, 'model__max_features': None, 'model__max_samples': 0.5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 50, 'model__warm_start': True}\n",
            "MSE: 0.1111\n",
            "MAE: 0.2357\n",
            "R2 Score: 0.8252\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Model: DecisionTreeRegressor\n",
            "Best Params: {'model__criterion': 'squared_error', 'model__max_depth': 20, 'model__max_features': 'log2', 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__splitter': 'best'}\n",
            "MSE: 0.2292\n",
            "MAE: 0.3061\n",
            "R2 Score: 0.6395\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acx_Jm3X1rfz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}